# robots.txt for www.dawidmacek.com

# Allow major search engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: DuckDuckBot
Allow: /

User-agent: Baiduspider
Allow: /

User-agent: YandexBot
Allow: /

# Block AI training and scraping bots
User-agent: GPTBot
Disallow: /

User-agent: Google-Extended
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: anthropic-ai
Disallow: /

User-agent: Claude-Web
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: OpenAI-SearchBot
Disallow: /

User-agent: PerplexityBot
Disallow: /

User-agent: YouBot
Disallow: /

User-agent: Meta-ExternalAgent
Disallow: /

User-agent: FacebookBot
Disallow: /

User-agent: Applebot-Extended
Disallow: /

User-agent: Diffbot
Disallow: /

User-agent: Bytespider
Disallow: /

User-agent: ImagesiftBot
Disallow: /

User-agent: Omgilibot
Disallow: /

User-agent: Omgili
Disallow: /

User-agent: webz.io
Disallow: /

User-agent: WebzIO-Extended
Disallow: /

User-agent: img2dataset
Disallow: /

User-agent: dataset
Disallow: /

User-agent: ISSCyberRiskCrawler
Disallow: /

User-agent: DataForSeoBot
Disallow: /

User-agent: VelenPublicWebCrawler
Disallow: /

User-agent: TurnitinBot
Disallow: /

# Block aggressive scrapers and research crawlers
User-agent: ia_archiver
Disallow: /

User-agent: ScrapingBot
Disallow: /

User-agent: DataMinr
Disallow: /

User-agent: PetalBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: 008
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: MauiBot
Disallow: /

# Default rule for unspecified bots (be more permissive for unknown legitimate crawlers)
User-agent: *
Allow: /

# Sitemap location
Sitemap: https://www.dawidmacek.com/sitemap.xml